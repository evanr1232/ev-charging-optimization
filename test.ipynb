{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "641b0a46",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/so/miniforge3/envs/sustaingym_ev/lib/python3.10/site-packages/ray/_private/parameter.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "2025-12-06 22:01:00,243\tWARNING __init__.py:10 -- PG has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading checkpoint from: logs/caltech_ppo_Summer 2021_lr0.0005_seed123/checkpoint_000050/policies/default_policy/policy_state.pkl\n",
            "Running 100 rollouts...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import gymnasium as gym\n",
        "from ray.rllib.algorithms.algorithm import Algorithm\n",
        "from ray.tune.registry import register_env\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sustaingym.algorithms.base import RLLibAlgorithm\n",
        "from sustaingym.envs.evcharging import (\n",
        "    EVChargingEnv, \n",
        "    GMMsTraceGenerator, \n",
        "    DiscreteActionWrapper\n",
        ")\n",
        "from ray.rllib.algorithms.ppo import PPOConfig\n",
        "import torch\n",
        "\n",
        "# Configuration\n",
        "CHECKPOINT_DIR = \"logs/caltech_ppo_Summer 2021_lr0.0005_seed123/checkpoint_000050/policies/default_policy/policy_state.pkl\"\n",
        "NUM_ROLLOUTS = 100\n",
        "SITE = \"caltech\"\n",
        "DATE_PERIOD = \"Summer 2021\"\n",
        "DATE_RANGE = (\"2021-07-05\", \"2021-07-18\")\n",
        "SEED = 123\n",
        "\n",
        "print(f\"Loading checkpoint from: {CHECKPOINT_DIR}\")\n",
        "print(f\"Running {NUM_ROLLOUTS} rollouts...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4545e006",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/so/miniforge3/envs/sustaingym_ev/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:484: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
            "`UnifiedLogger` will be removed in Ray 2.7.\n",
            "  return UnifiedLogger(config, logdir, loggers=None)\n",
            "/Users/so/miniforge3/envs/sustaingym_ev/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
            "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
            "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
            "/Users/so/miniforge3/envs/sustaingym_ev/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
            "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
            "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
            "/Users/so/miniforge3/envs/sustaingym_ev/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
            "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
            "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
            "2025-12-06 22:01:00,385\tWARNING env.py:162 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
            "2025-12-06 22:01:00,696\tWARNING util.py:62 -- Install gputil for GPU system monitoring.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Module state file not found at logs/caltech_ppo_Summer 2021_lr0.0005_seed123/checkpoint_000050/policies/default_policy/policy_state.pkl/learner/module_state/default_policy/module_state_dir/module_state.pt\n",
            "Attempting to use algorithm without loading weights...\n",
            "Algorithm ready!\n",
            "Algorithm type: <class 'ray.rllib.algorithms.ppo.ppo.PPO'>\n"
          ]
        }
      ],
      "source": [
        "def make_env():\n",
        "    \"\"\"Create environment matching training configuration.\"\"\"\n",
        "    gen = GMMsTraceGenerator(SITE, DATE_RANGE, seed=SEED)\n",
        "    env = EVChargingEnv(gen)\n",
        "    env = DiscreteActionWrapper(gym.wrappers.FlattenObservation(env))\n",
        "    return env\n",
        "\n",
        "register_env(\"evcharging\", lambda config: make_env())\n",
        "\n",
        "train_config = (\n",
        "    PPOConfig()\n",
        "    .environment(env=\"evcharging\")\n",
        "    .rollouts(num_rollout_workers=0)  # Match training config\n",
        "    .framework(\"torch\")\n",
        ")\n",
        "\n",
        "algo = train_config.build(env=\"evcharging\")\n",
        "\n",
        "# Load policy weights directly from module_state.pt\n",
        "module_state_path = os.path.join(\n",
        "    CHECKPOINT_DIR, \n",
        "    \"learner\", \n",
        "    \"module_state\", \n",
        "    \"default_policy\", \n",
        "    \"module_state_dir\", \n",
        "    \"module_state.pt\"\n",
        ")\n",
        "\n",
        "if os.path.exists(module_state_path):\n",
        "    print(f\"Loading policy weights from: {module_state_path}\")\n",
        "    policy = algo.get_policy()\n",
        "    \n",
        "    state_dict = torch.load(module_state_path, map_location=\"cpu\")\n",
        "    \n",
        "    # The state dict might have a nested structure, so we need to extract the model weights\n",
        "    # For RLLib policies, the model is usually at the top level or nested\n",
        "    if isinstance(state_dict, dict):\n",
        "        # Try to find model weights - they might be under different keys\n",
        "        # Common patterns: direct keys, or nested under 'model' or similar\n",
        "        model_state = {}\n",
        "        for key, value in state_dict.items():\n",
        "            # Skip non-model keys (like optimizer state, etc.)\n",
        "            if not any(skip in key.lower() for skip in ['optimizer', 'scheduler', 'step', 'epoch']):\n",
        "                model_state[key] = value\n",
        "        \n",
        "        # Load into policy model\n",
        "        try:\n",
        "            policy.model.load_state_dict(model_state, strict=False)\n",
        "            print(\"Successfully loaded policy weights!\")\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not load all weights: {e}\")\n",
        "            # Try loading with strict=False to allow partial loading\n",
        "            try:\n",
        "                policy.model.load_state_dict(state_dict, strict=False)\n",
        "                print(\"Loaded weights with strict=False (some weights may not match)\")\n",
        "            except Exception as e2:\n",
        "                print(f\"Failed to load weights: {e2}\")\n",
        "                raise\n",
        "    else:\n",
        "        # If it's not a dict, try loading directly\n",
        "        policy.model.load_state_dict(state_dict, strict=False)\n",
        "        print(\"Successfully loaded policy weights!\")\n",
        "else:\n",
        "    print(f\"Warning: Module state file not found at {module_state_path}\")\n",
        "    print(\"Attempting to use algorithm without loading weights...\")\n",
        "\n",
        "print(\"Algorithm ready!\")\n",
        "print(f\"Algorithm type: {type(algo)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8259b2f8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting rollouts...\n"
          ]
        }
      ],
      "source": [
        "# Create environment and algorithm wrapper\n",
        "env = make_env()\n",
        "rllib_algo = RLLibAlgorithm(env, algo, multiagent=False)\n",
        "\n",
        "# Storage for metrics\n",
        "all_rewards = []\n",
        "all_profits = []  # Power delivery (profit component)\n",
        "all_carbon_costs = []  # Carbon cost component\n",
        "all_constraint_violations = []  # Constraint violation cost component\n",
        "power_by_hour = defaultdict(list)  # hour -> list of total power (Amps) at that hour\n",
        "moer_by_hour = defaultdict(list)  # hour -> list of MOER values at that hour\n",
        "demand_by_station_by_hour = defaultdict(lambda: defaultdict(list))  # station_idx -> hour -> list of demands (kWh)\n",
        "\n",
        "# Store individual rollout data for finding high evening demand rollouts\n",
        "individual_rollout_demands = []  # List of dicts: {rollout_idx, demand_by_hour, power_by_hour, moer_by_hour}\n",
        "\n",
        "print(\"Starting rollouts...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bada6fa1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running 100 rollouts sequentially...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running rollouts:   0%|          | 0/100 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "The two structures don't have the same nested structure.\n\nFirst structure: type=list str=[2, 0, 4, 0, 3, 2, 4, 3, 2, 3, 4, 0, 4, 1, 4, 3, 3, 3, 3, 1, 0, 0, 2, 0, 4, 2, 0, 2, 1, 1, 4, 2, 3, 0, 0, 2, 3, 4, 2, 4, 3, 3, 0, 2, 2, 4, 3, 0, 4, 2, 3, 3, 1, 3]\n\nSecond structure: type=MultiDiscrete str=MultiDiscrete([5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5])\n\nMore specifically: Substructure \"type=list str=[2, 0, 4, 0, 3, 2, 4, 3, 2, 3, 4, 0, 4, 1, 4, 3, 3, 3, 3, 1, 0, 0, 2, 0, 4, 2, 0, 2, 1, 1, 4, 2, 3, 0, 0, 2, 3, 4, 2, 4, 3, 3, 0, 2, 2, 4, 3, 0, 4, 2, 3, 3, 1, 3]\" is a sequence, while substructure \"type=MultiDiscrete str=MultiDiscrete([5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5])\" is not\nEntire first structure:\n[., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., .]\nEntire second structure:\n.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "File \u001b[0;32m~/miniforge3/envs/sustaingym_ev/lib/python3.10/site-packages/tree/__init__.py:277\u001b[0m, in \u001b[0;36massert_same_structure\u001b[0;34m(a, b, check_types)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 277\u001b[0m   \u001b[43m_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_same_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_types\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[0;31mValueError\u001b[0m: The two structures don't have the same nested structure.\n\nFirst structure: type=list str=[2, 0, 4, 0, 3, 2, 4, 3, 2, 3, 4, 0, 4, 1, 4, 3, 3, 3, 3, 1, 0, 0, 2, 0, 4, 2, 0, 2, 1, 1, 4, 2, 3, 0, 0, 2, 3, 4, 2, 4, 3, 3, 0, 2, 2, 4, 3, 0, 4, 2, 3, 3, 1, 3]\n\nSecond structure: type=MultiDiscrete str=MultiDiscrete([5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5])\n\nMore specifically: Substructure \"type=list str=[2, 0, 4, 0, 3, 2, 4, 3, 2, 3, 4, 0, 4, 1, 4, 3, 3, 3, 3, 1, 0, 0, 2, 0, 4, 2, 0, 2, 1, 1, 4, 2, 3, 0, 0, 2, 3, 4, 2, 4, 3, 3, 0, 2, 2, 4, 3, 0, 4, 2, 3, 3, 1, 3]\" is a sequence, while substructure \"type=MultiDiscrete str=MultiDiscrete([5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5])\" is not",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Get action from policy\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mrllib_algo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Step environment\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n",
            "File \u001b[0;32m~/miniforge3/envs/sustaingym_ev/lib/python3.10/site-packages/sustaingym/algorithms/base.py:126\u001b[0m, in \u001b[0;36mRLLibAlgorithm.get_action\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    123\u001b[0m             action[agent_id] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgo\u001b[38;5;241m.\u001b[39mcompute_single_action(\n\u001b[1;32m    124\u001b[0m                 agent_obs, policy_id\u001b[38;5;241m=\u001b[39mpolicy_id, explore\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_single_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action\n",
            "File \u001b[0;32m~/miniforge3/envs/sustaingym_ev/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:1659\u001b[0m, in \u001b[0;36mAlgorithm.compute_single_action\u001b[0;34m(self, observation, state, prev_action, prev_reward, info, input_dict, policy_id, full_fetch, explore, timestep, episode, unsquash_action, clip_action, **kwargs)\u001b[0m\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;66;03m# If we work in normalized action space (normalize_actions=True),\u001b[39;00m\n\u001b[1;32m   1657\u001b[0m \u001b[38;5;66;03m# we re-translate here into the env's action space.\u001b[39;00m\n\u001b[1;32m   1658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unsquash_action:\n\u001b[0;32m-> 1659\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mspace_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsquash_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_space_struct\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1660\u001b[0m \u001b[38;5;66;03m# Clip, according to env's action space.\u001b[39;00m\n\u001b[1;32m   1661\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m clip_action:\n",
            "File \u001b[0;32m~/miniforge3/envs/sustaingym_ev/lib/python3.10/site-packages/ray/rllib/utils/spaces/space_utils.py:306\u001b[0m, in \u001b[0;36munsquash_action\u001b[0;34m(action, action_space_struct)\u001b[0m\n\u001b[1;32m    303\u001b[0m             a \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mlow \u001b[38;5;241m+\u001b[39m a\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmap_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_space_struct\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniforge3/envs/sustaingym_ev/lib/python3.10/site-packages/tree/__init__.py:426\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structures, **kwargs)\u001b[0m\n\u001b[1;32m    421\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    422\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly valid keyword arguments are `check_types` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    423\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot: `\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`, `\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(kwargs\u001b[38;5;241m.\u001b[39mkeys())))\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m structures[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m--> 426\u001b[0m   \u001b[43massert_same_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstructures\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_types\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unflatten_as(structures[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    428\u001b[0m                     [func(\u001b[38;5;241m*\u001b[39margs) \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(flatten, structures))])\n",
            "File \u001b[0;32m~/miniforge3/envs/sustaingym_ev/lib/python3.10/site-packages/tree/__init__.py:281\u001b[0m, in \u001b[0;36massert_same_structure\u001b[0;34m(a, b, check_types)\u001b[0m\n\u001b[1;32m    279\u001b[0m str1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(map_structure(\u001b[38;5;28;01mlambda\u001b[39;00m _: _DOT, a))\n\u001b[1;32m    280\u001b[0m str2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(map_structure(\u001b[38;5;28;01mlambda\u001b[39;00m _: _DOT, b))\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntire first structure:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntire second structure:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m               \u001b[38;5;241m%\u001b[39m (e, str1, str2))\n",
            "\u001b[0;31mValueError\u001b[0m: The two structures don't have the same nested structure.\n\nFirst structure: type=list str=[2, 0, 4, 0, 3, 2, 4, 3, 2, 3, 4, 0, 4, 1, 4, 3, 3, 3, 3, 1, 0, 0, 2, 0, 4, 2, 0, 2, 1, 1, 4, 2, 3, 0, 0, 2, 3, 4, 2, 4, 3, 3, 0, 2, 2, 4, 3, 0, 4, 2, 3, 3, 1, 3]\n\nSecond structure: type=MultiDiscrete str=MultiDiscrete([5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5])\n\nMore specifically: Substructure \"type=list str=[2, 0, 4, 0, 3, 2, 4, 3, 2, 3, 4, 0, 4, 1, 4, 3, 3, 3, 3, 1, 0, 0, 2, 0, 4, 2, 0, 2, 1, 1, 4, 2, 3, 0, 0, 2, 3, 4, 2, 4, 3, 3, 0, 2, 2, 4, 3, 0, 4, 2, 3, 3, 1, 3]\" is a sequence, while substructure \"type=MultiDiscrete str=MultiDiscrete([5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5])\" is not\nEntire first structure:\n[., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., .]\nEntire second structure:\n."
          ]
        }
      ],
      "source": [
        "# Run rollouts sequentially\n",
        "print(f\"Running {NUM_ROLLOUTS} rollouts sequentially...\")\n",
        "\n",
        "for rollout_idx in tqdm(range(NUM_ROLLOUTS), desc=\"Running rollouts\"):\n",
        "    obs, _ = env.reset(seed=rollout_idx)\n",
        "    rllib_algo.reset()\n",
        "    \n",
        "    episode_reward = 0.0\n",
        "    episode_power_by_timestep = []\n",
        "    episode_moer_by_timestep = []\n",
        "    episode_demands_by_timestep = []\n",
        "    \n",
        "    done = False\n",
        "    \n",
        "    while not done:\n",
        "        # Get action from policy\n",
        "        action = rllib_algo.get_action(obs)\n",
        "        \n",
        "        # Step environment\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "        done = terminated or truncated\n",
        "        \n",
        "        episode_reward += reward\n",
        "        \n",
        "        # Collect power profile data\n",
        "        # Access the simulator's charging rates\n",
        "        # Unwrap: DiscreteActionWrapper -> FlattenObservation -> EVChargingEnv\n",
        "        actual_env = env.env.env  # Get the actual EVChargingEnv\n",
        "        if hasattr(actual_env, '_simulator') and hasattr(actual_env, 't'):\n",
        "            # Get charging rates for current timestep\n",
        "            # t is already incremented in step(), so current timestep is t-1\n",
        "            current_timestep = actual_env.t - 1\n",
        "            if current_timestep >= 0 and current_timestep < actual_env._simulator.charging_rates.shape[1]:\n",
        "                total_power = np.sum(actual_env._simulator.charging_rates[:, current_timestep])\n",
        "                episode_power_by_timestep.append(total_power)\n",
        "        \n",
        "        # Collect MOER data from environment\n",
        "        # Get MOER from environment's moer array (shape [289, 37])\n",
        "        if hasattr(actual_env, 'moer') and hasattr(actual_env, 't'):\n",
        "            current_timestep = actual_env.t - 1\n",
        "            if current_timestep >= 0 and current_timestep < actual_env.moer.shape[0]:\n",
        "                moer_value = actual_env.moer[current_timestep, 0]  # Current timestep's MOER\n",
        "                episode_moer_by_timestep.append(moer_value)\n",
        "        \n",
        "        # Collect demand data per station\n",
        "        # Demands are in the environment's _demands array (shape [num_stations])\n",
        "        if hasattr(actual_env, '_demands'):\n",
        "            demands = actual_env._demands.copy()  # Copy to avoid reference issues\n",
        "            episode_demands_by_timestep.append(demands)\n",
        "    \n",
        "    all_rewards.append(episode_reward)\n",
        "    \n",
        "    # Collect reward breakdown components at end of episode\n",
        "    # The reward_breakdown is cumulative over the episode\n",
        "    actual_env = env.env.env  # Get the actual EVChargingEnv\n",
        "    if hasattr(actual_env, '_reward_breakdown'):\n",
        "        reward_breakdown = actual_env._reward_breakdown\n",
        "        episode_profit = reward_breakdown.get('profit', 0.0)\n",
        "        episode_carbon_cost = reward_breakdown.get('carbon_cost', 0.0)\n",
        "        episode_constraint_violation = reward_breakdown.get('excess_charge', 0.0)\n",
        "        \n",
        "        all_profits.append(episode_profit)\n",
        "        all_carbon_costs.append(episode_carbon_cost)\n",
        "        all_constraint_violations.append(episode_constraint_violation)\n",
        "    else:\n",
        "        # Fallback: try to get from info dict (if available at last step)\n",
        "        # This is a fallback, but info dict might not be available after episode ends\n",
        "        all_profits.append(0.0)\n",
        "        all_carbon_costs.append(0.0)\n",
        "        all_constraint_violations.append(0.0)\n",
        "    \n",
        "    # Convert timesteps to hours of day and aggregate\n",
        "    # Each timestep is 5 minutes, so 12 timesteps = 1 hour\n",
        "    # timestep 0 = midnight, timestep 288 = next midnight\n",
        "    for ts_idx, power in enumerate(episode_power_by_timestep):\n",
        "        hour_of_day = (ts_idx * 5) / 60  # Convert 5-min timesteps to hours\n",
        "        hour_of_day = int(hour_of_day) % 24  # Ensure 0-23 range\n",
        "        power_by_hour[hour_of_day].append(power)\n",
        "    \n",
        "    # Aggregate MOER by hour\n",
        "    for ts_idx, moer in enumerate(episode_moer_by_timestep):\n",
        "        hour_of_day = (ts_idx * 5) / 60  # Convert 5-min timesteps to hours\n",
        "        hour_of_day = int(hour_of_day) % 24  # Ensure 0-23 range\n",
        "        moer_by_hour[hour_of_day].append(moer)\n",
        "    \n",
        "    # Aggregate demands by station and hour\n",
        "    for ts_idx, demands in enumerate(episode_demands_by_timestep):\n",
        "        hour_of_day = (ts_idx * 5) / 60  # Convert 5-min timesteps to hours\n",
        "        hour_of_day = int(hour_of_day) % 24  # Ensure 0-23 range\n",
        "        for station_idx, demand in enumerate(demands):\n",
        "            demand_by_station_by_hour[station_idx][hour_of_day].append(demand)\n",
        "    \n",
        "    # Store individual rollout data (aggregated across stations by hour)\n",
        "    rollout_demand_by_hour = defaultdict(list)\n",
        "    rollout_power_by_hour = defaultdict(list)\n",
        "    rollout_moer_by_hour = defaultdict(list)\n",
        "    \n",
        "    for ts_idx, demands in enumerate(episode_demands_by_timestep):\n",
        "        hour_of_day = (ts_idx * 5) / 60  # Convert 5-min timesteps to hours\n",
        "        hour_of_day = int(hour_of_day) % 24  # Ensure 0-23 range\n",
        "        # Sum demand across all stations for this timestep\n",
        "        total_demand = np.sum(demands)\n",
        "        rollout_demand_by_hour[hour_of_day].append(total_demand)\n",
        "        \n",
        "        # Store power and MOER for this timestep\n",
        "        if ts_idx < len(episode_power_by_timestep):\n",
        "            rollout_power_by_hour[hour_of_day].append(episode_power_by_timestep[ts_idx])\n",
        "        if ts_idx < len(episode_moer_by_timestep):\n",
        "            rollout_moer_by_hour[hour_of_day].append(episode_moer_by_timestep[ts_idx])\n",
        "    \n",
        "    # Calculate average per hour for this rollout\n",
        "    rollout_avg_demand_by_hour = {}\n",
        "    rollout_avg_power_by_hour = {}\n",
        "    rollout_avg_moer_by_hour = {}\n",
        "    \n",
        "    for hour in range(24):\n",
        "        if hour in rollout_demand_by_hour and len(rollout_demand_by_hour[hour]) > 0:\n",
        "            rollout_avg_demand_by_hour[hour] = np.mean(rollout_demand_by_hour[hour])\n",
        "        else:\n",
        "            rollout_avg_demand_by_hour[hour] = 0.0\n",
        "        \n",
        "        if hour in rollout_power_by_hour and len(rollout_power_by_hour[hour]) > 0:\n",
        "            rollout_avg_power_by_hour[hour] = np.mean(rollout_power_by_hour[hour])\n",
        "        else:\n",
        "            rollout_avg_power_by_hour[hour] = 0.0\n",
        "        \n",
        "        if hour in rollout_moer_by_hour and len(rollout_moer_by_hour[hour]) > 0:\n",
        "            rollout_avg_moer_by_hour[hour] = np.mean(rollout_moer_by_hour[hour])\n",
        "        else:\n",
        "            rollout_avg_moer_by_hour[hour] = 0.0\n",
        "    \n",
        "    individual_rollout_demands.append({\n",
        "        'rollout_idx': rollout_idx,\n",
        "        'demand_by_hour': rollout_avg_demand_by_hour,\n",
        "        'power_by_hour': rollout_avg_power_by_hour,\n",
        "        'moer_by_hour': rollout_avg_moer_by_hour\n",
        "    })\n",
        "\n",
        "print(f\"Completed {NUM_ROLLOUTS} rollouts!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe7c9b87",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate average reward\n",
        "avg_reward = np.mean(all_rewards)\n",
        "std_reward = np.std(all_rewards)\n",
        "min_reward = np.min(all_rewards)\n",
        "max_reward = np.max(all_rewards)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"METRICS SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Average Reward: ${avg_reward:.2f}\")\n",
        "print(f\"Std Reward: ${std_reward:.2f}\")\n",
        "print(f\"Min Reward: ${min_reward:.2f}\")\n",
        "print(f\"Max Reward: ${max_reward:.2f}\")\n",
        "print(f\"Number of Rollouts: {NUM_ROLLOUTS}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6026c02e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate disaggregated reward components\n",
        "avg_profit = np.mean(all_profits) if len(all_profits) > 0 else 0.0\n",
        "avg_carbon_cost = np.mean(all_carbon_costs) if len(all_carbon_costs) > 0 else 0.0\n",
        "avg_constraint_violation = np.mean(all_constraint_violations) if len(all_constraint_violations) > 0 else 0.0\n",
        "avg_total_reward = np.mean(all_rewards)\n",
        "\n",
        "# Create table for disaggregated rewards\n",
        "reward_breakdown_data = {\n",
        "    'Algorithm': ['PPO'],\n",
        "    'Avg. Power Delivery': [f'{avg_profit:.4f}'],\n",
        "    'Avg. Carbon Cost': [f'{avg_carbon_cost:.4f}'],\n",
        "    'Avg. Constr. Violation': [f'{avg_constraint_violation:.4f}'],\n",
        "    'Avg. Total Reward': [f'{avg_total_reward:.4f}']\n",
        "}\n",
        "\n",
        "reward_breakdown_df = pd.DataFrame(reward_breakdown_data)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"=\" * 80)\n",
        "print(reward_breakdown_df.to_string(index=False))\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nNote: Power Delivery (profit) is positive, Carbon Cost and Constraint Violation are costs (negative in reward)\")\n",
        "print(f\"Total Reward = Power Delivery - Carbon Cost - Constraint Violation\")\n",
        "print(f\"Verification: {avg_profit:.4f} - {avg_carbon_cost:.4f} - {avg_constraint_violation:.4f} = {avg_profit - avg_carbon_cost - avg_constraint_violation:.4f}\")\n",
        "print(f\"Actual Average Total Reward: {avg_total_reward:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a5b176a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate power profile by time of day\n",
        "power_profile_data = []\n",
        "for hour in range(24):\n",
        "    if hour in power_by_hour:\n",
        "        avg_power = np.mean(power_by_hour[hour])\n",
        "        std_power = np.std(power_by_hour[hour])\n",
        "        power_profile_data.append({\n",
        "            'hour': hour,\n",
        "            'avg_power_amps': avg_power,\n",
        "            'std_power_amps': std_power,\n",
        "            'num_samples': len(power_by_hour[hour])\n",
        "        })\n",
        "    else:\n",
        "        power_profile_data.append({\n",
        "            'hour': hour,\n",
        "            'avg_power_amps': 0.0,\n",
        "            'std_power_amps': 0.0,\n",
        "            'num_samples': 0\n",
        "        })\n",
        "\n",
        "power_profile_df = pd.DataFrame(power_profile_data)\n",
        "\n",
        "# Calculate MOER profile by time of day\n",
        "moer_profile_data = []\n",
        "for hour in range(24):\n",
        "    if hour in moer_by_hour:\n",
        "        avg_moer = np.mean(moer_by_hour[hour])\n",
        "        std_moer = np.std(moer_by_hour[hour])\n",
        "        moer_profile_data.append({\n",
        "            'hour': hour,\n",
        "            'avg_moer': avg_moer,\n",
        "            'std_moer': std_moer,\n",
        "            'num_samples': len(moer_by_hour[hour])\n",
        "        })\n",
        "    else:\n",
        "        moer_profile_data.append({\n",
        "            'hour': hour,\n",
        "            'avg_moer': 0.0,\n",
        "            'std_moer': 0.0,\n",
        "            'num_samples': 0\n",
        "        })\n",
        "\n",
        "moer_profile_df = pd.DataFrame(moer_profile_data)\n",
        "\n",
        "print(\"\\nPower Profile by Time of Day:\")\n",
        "print(power_profile_df.to_string(index=False))\n",
        "print(\"\\nMOER Profile by Time of Day:\")\n",
        "print(moer_profile_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "294313df",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize power profile, MOER, and station demand\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Find a rollout with high evening demand (hours 16-22)\n",
        "evening_hours = list(range(16, 23))  # 4 PM to 10 PM\n",
        "rollout_evening_demands = []\n",
        "for rollout_data in individual_rollout_demands:\n",
        "    evening_demand = sum(rollout_data['demand_by_hour'].get(hour, 0.0) for hour in evening_hours)\n",
        "    rollout_evening_demands.append({\n",
        "        'rollout_idx': rollout_data['rollout_idx'],\n",
        "        'evening_demand': evening_demand,\n",
        "        'demand_by_hour': rollout_data['demand_by_hour']\n",
        "    })\n",
        "\n",
        "# Sort by evening demand and pick the one with highest evening demand\n",
        "rollout_evening_demands.sort(key=lambda x: x['evening_demand'], reverse=True)\n",
        "high_evening_rollout = rollout_evening_demands[0]\n",
        "\n",
        "print(f\"Selected rollout {high_evening_rollout['rollout_idx']} with evening demand: {high_evening_rollout['evening_demand']:.2f} kWh\")\n",
        "\n",
        "# Create figure with three subplots\n",
        "fig = plt.figure(figsize=(14, 14))\n",
        "\n",
        "# Top subplot: Power and MOER\n",
        "ax1 = plt.subplot(2, 1, 1)\n",
        "hours = power_profile_df['hour']\n",
        "avg_power = power_profile_df['avg_power_amps']\n",
        "std_power = power_profile_df['std_power_amps']\n",
        "avg_moer = moer_profile_df['avg_moer']\n",
        "std_moer = moer_profile_df['std_moer']\n",
        "\n",
        "# Plot power on left y-axis\n",
        "color1 = 'tab:blue'\n",
        "ax1.set_xlabel('Hour of Day', fontsize=12)\n",
        "ax1.set_ylabel('Current (Amps)', fontsize=12, color=color1)\n",
        "line1 = ax1.plot(hours, avg_power, color=color1, linewidth=2, label='Average Power')\n",
        "# ax1.fill_between(hours, avg_power - std_power, avg_power + std_power, \n",
        "#                 alpha=0.3, color=color1, label='Power ±1 Std Dev')\n",
        "ax1.tick_params(axis='y', labelcolor=color1)\n",
        "ax1.set_xticks(range(0, 24, 2))\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_xlim(0, 23)\n",
        "\n",
        "# Plot MOER on right y-axis\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "color2 = 'tab:red'\n",
        "ax2.set_ylabel('MOER (kg CO2 / kWh)', fontsize=12, color=color2)\n",
        "line2 = ax2.plot(hours, avg_moer, color=color2, linewidth=2, linestyle='--', label='Average MOER')\n",
        "# ax2.fill_between(hours, avg_moer - std_moer, avg_moer + std_moer, \n",
        "#                 alpha=0.2, color=color2, label='MOER ±1 Std Dev')\n",
        "ax2.tick_params(axis='y', labelcolor=color2)\n",
        "\n",
        "# Combine legends\n",
        "lines = line1 + line2\n",
        "labels = [l.get_label() for l in lines]\n",
        "ax1.legend(lines, labels, loc='upper left')\n",
        "\n",
        "ax1.set_title(f'Current Profile and MOER by Time of Day', fontsize=14)\n",
        "\n",
        "# Bottom subplot: Station demand over time (time series)\n",
        "ax3 = plt.subplot(2, 1, 2)\n",
        "\n",
        "# Calculate average demand across all stations for each hour\n",
        "demand_by_hour_avg = []\n",
        "demand_by_hour_std = []\n",
        "\n",
        "for hour in range(24):\n",
        "    # Collect all demand values for this hour across all stations\n",
        "    hour_demands = []\n",
        "    for station_idx in demand_by_station_by_hour:\n",
        "        if hour in demand_by_station_by_hour[station_idx]:\n",
        "            hour_demands.extend(demand_by_station_by_hour[station_idx][hour])\n",
        "    \n",
        "    if hour_demands:\n",
        "        demand_by_hour_avg.append(np.mean(hour_demands))\n",
        "        demand_by_hour_std.append(np.std(hour_demands))\n",
        "    else:\n",
        "        demand_by_hour_avg.append(0.0)\n",
        "        demand_by_hour_std.append(0.0)\n",
        "\n",
        "# Create time series plot\n",
        "ax3.plot(hours, demand_by_hour_avg, color='tab:green', linewidth=2, label='Average Demand')\n",
        "# ax3.fill_between(hours, \n",
        "#                  np.array(demand_by_hour_avg) - np.array(demand_by_hour_std),\n",
        "#                  np.array(demand_by_hour_avg) + np.array(demand_by_hour_std),\n",
        "#                  alpha=0.3, color='tab:green', label='±1 Std Dev')\n",
        "\n",
        "ax3.set_xlabel('Hour of Day', fontsize=12)\n",
        "ax3.set_ylabel('Average Demand (kWh)', fontsize=12)\n",
        "ax3.set_title(f'Average Station Demand by Time of Day', fontsize=14)\n",
        "ax3.set_xticks(range(0, 24, 2))\n",
        "ax3.set_xticklabels(range(0, 24, 2))\n",
        "ax3.grid(True, alpha=0.3)\n",
        "ax3.set_xlim(0, 23)\n",
        "ax3.legend(loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nAverage total power across all hours: {avg_power.mean():.2f} Amps\")\n",
        "print(f\"Average MOER across all hours: {avg_moer.mean():.4f} kg CO2 / kWh\")\n",
        "print(f\"Average demand across all stations and hours: {np.mean(demand_by_hour_avg):.2f} kWh\")\n",
        "print(f\"Peak demand hour: {np.argmax(demand_by_hour_avg)}:00 ({max(demand_by_hour_avg):.2f} kWh)\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sustaingym_ev",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
